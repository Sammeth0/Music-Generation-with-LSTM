{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Music gereration with Keras and LSTM\n",
    "\n",
    "1. Read midi file, convert it to matrix of features\n",
    "2. Create simple model with Keras and LSTM to learn the pattern\n",
    "3. Use subsample of initial midi file as an input for model\n",
    "4. Save prediction from model to midi file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile('TheBeatlesIWantYou.mid') \n",
    "notes = []\n",
    "velocities = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract notes and velocities and then compine it in the one list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for msg in mid:\n",
    "    if not msg.is_meta:\n",
    "        if msg.channel == 0:\n",
    "            if msg.type == 'note_on':\n",
    "                data = msg.bytes()\n",
    "                # append note and velocity from [type, note, velocity]\n",
    "                note = data[1]\n",
    "                velocity = data[2]\n",
    "                notes.append(note)\n",
    "                velocities.append(velocity)\n",
    "combine = [[i,j] for i,j in zip(notes, velocities) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_min = np.min(notes)\n",
    "note_max = np.max(notes)\n",
    "velocities_min = np.min(velocities)\n",
    "velocities_max = np.max(velocities)\n",
    "\n",
    "for i in combine:\n",
    "    i[0] = 2*(i[0]-((note_min+note_max)/2))/(note_max-note_min)\n",
    "    i[1] = 2*(i[1]-((velocities_min+velocities_max)/2))/(velocities_max-velocities_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare features for training and data subsample for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "n_prev = 30\n",
    "for i in range(len(combine)-n_prev):\n",
    "    x = combine[i:i+n_prev]\n",
    "    y = combine[i+n_prev]\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "# save a seed to do prediction later\n",
    "seed = combine[0:n_prev]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Made sequential model with several layers, use LSTM as it time dependent data\n",
    "\n",
    "I also want to save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(n_prev, 2), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, input_shape=(n_prev, 2), return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64, input_shape=(n_prev, 2), return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('linear'))\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "filepath=\"./checkpoint_model_{epoch:02d}.hdf5\"\n",
    "model_save_callback = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                                      verbose=1, save_best_only=False, \n",
    "                                      mode='auto', period=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1994/1994 [==============================] - 141s 71ms/step - loss: 0.5483\n",
      "Epoch 2/5\n",
      "1994/1994 [==============================] - 85s 43ms/step - loss: 0.1309\n",
      "Epoch 3/5\n",
      "1994/1994 [==============================] - 85s 43ms/step - loss: 0.0838\n",
      "Epoch 4/5\n",
      "1994/1994 [==============================] - 99s 50ms/step - loss: 0.0721\n",
      "Epoch 5/5\n",
      "1992/1994 [============================>.] - ETA: 0s - loss: 0.0647Epoch 00005: saving model to ./checkpoint_model_05.hdf5\n",
      "1994/1994 [==============================] - 160s 80ms/step - loss: 0.0647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e7e9419908>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X), np.array(Y), 2, 5, verbose=1, callbacks=[model_save_callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "x = seed\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "for i in range(300):\n",
    "    preds = model.predict(x)\n",
    "    x = np.squeeze(x)\n",
    "    x = np.concatenate((x, preds))\n",
    "    x = x[1:]\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = np.squeeze(preds)\n",
    "    prediction.append(preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse the min-max scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in prediction:\n",
    "# Undo the preprocessing\n",
    "    pred[0] = int((pred[0]/2)*(note_max-note_min) + (note_min+note_max)/2)\n",
    "    pred[1] = int((pred[1]/2)*(velocities_max-velocities_min) + (velocities_min+velocities_max)/2)\n",
    "    if pred[0] < 24:\n",
    "        pred[0] = 24\n",
    "    elif pred[0] > 102:\n",
    "        pred[0] = 102\n",
    "    if pred[1] < 0:\n",
    "        pred[1] = 0\n",
    "    elif pred[1] > 127:\n",
    "        pred[1] = 127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save your result to new midi file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "\n",
    "t = 0\n",
    "for note in prediction:\n",
    "    # 147 means note_on\n",
    "    note = np.asarray([147, note[0], note[1]])\n",
    "    bytes = note.astype(int)\n",
    "    msg = Message.from_bytes(bytes[0:3])\n",
    "    t += 1\n",
    "    msg.time = t\n",
    "    track.append(msg)\n",
    "\n",
    "mid.tracks.append(track)\n",
    "mid.save('Generated_song.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, just listen to it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
